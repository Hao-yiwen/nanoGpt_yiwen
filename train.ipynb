{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9773ac",
   "metadata": {},
   "source": [
    "# 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ffa85c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-07 20:38:47--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt.1’\n",
      "\n",
      "input.txt.1         100%[===================>]   1.06M  1.03MB/s    in 1.0s    \n",
      "\n",
      "2025-12-07 20:38:49 (1.03 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5faf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77311a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb765aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2935502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16bc9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "# 这里，我们为字符集中的每个字符分配一个唯一的数字ID\n",
    "stoi = { ch:i for i,ch in enumerate(chars)}    # 字符到索引（string to index）的映射\n",
    "itos = { i:ch for i,ch in enumerate(chars)}    # 索引到字符（index to string）的映射\n",
    "\n",
    "# 定义一个编码函数，将字符串转换为数字ID序列，方便神经网络处理\n",
    "encodec = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encodec(\"hello\"))\n",
    "print(decode(encodec(\"hello\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8bc131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encodec(text), dtype=torch.long)\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c5863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6e2d43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45818b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]) the target is 47\n",
      "when input is tensor([18, 47]) the target is 56\n",
      "when input is tensor([18, 47, 56]) the target is 57\n",
      "when input is tensor([18, 47, 56, 57]) the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]) the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]) the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a423c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8]) \n",
      " torch.Size([4, 8])\n",
      "when input is tensor([24]) the target is 43\n",
      "when input is tensor([24, 43]) the target is 58\n",
      "when input is tensor([24, 43, 58]) the target is 5\n",
      "when input is tensor([24, 43, 58,  5]) the target is 57\n",
      "when input is tensor([24, 43, 58,  5, 57]) the target is 1\n",
      "when input is tensor([24, 43, 58,  5, 57,  1]) the target is 46\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46]) the target is 43\n",
      "when input is tensor([24, 43, 58,  5, 57,  1, 46, 43]) the target is 39\n",
      "when input is tensor([44]) the target is 53\n",
      "when input is tensor([44, 53]) the target is 56\n",
      "when input is tensor([44, 53, 56]) the target is 1\n",
      "when input is tensor([44, 53, 56,  1]) the target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58]) the target is 46\n",
      "when input is tensor([44, 53, 56,  1, 58, 46]) the target is 39\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39]) the target is 58\n",
      "when input is tensor([44, 53, 56,  1, 58, 46, 39, 58]) the target is 1\n",
      "when input is tensor([52]) the target is 58\n",
      "when input is tensor([52, 58]) the target is 1\n",
      "when input is tensor([52, 58,  1]) the target is 58\n",
      "when input is tensor([52, 58,  1, 58]) the target is 46\n",
      "when input is tensor([52, 58,  1, 58, 46]) the target is 39\n",
      "when input is tensor([52, 58,  1, 58, 46, 39]) the target is 58\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58]) the target is 1\n",
      "when input is tensor([52, 58,  1, 58, 46, 39, 58,  1]) the target is 46\n",
      "when input is tensor([25]) the target is 17\n",
      "when input is tensor([25, 17]) the target is 27\n",
      "when input is tensor([25, 17, 27]) the target is 10\n",
      "when input is tensor([25, 17, 27, 10]) the target is 0\n",
      "when input is tensor([25, 17, 27, 10,  0]) the target is 21\n",
      "when input is tensor([25, 17, 27, 10,  0, 21]) the target is 1\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1]) the target is 54\n",
      "when input is tensor([25, 17, 27, 10,  0, 21,  1, 54]) the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(xb.shape, '\\n', yb.shape)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context} the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcae5128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdc5514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "torch.Size([32, 65])\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# 定义一个“大ram语言模型”类，继承自nn.Module，表示一个能基于前一个词预测下一个词的神经网络模型\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embeding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embeding_table(idx)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            # https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html\n",
    "            \n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "        \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # self(idx) 的作用是调用模型的 forward 方法，等价于 self.forward(idx)\n",
    "            # 它返回 (logits, loss)，这里只关心 logits 部分\n",
    "            logits, _ = self(idx)\n",
    "            # logits的返回是在BigramLanguageModel.forward方法里，\n",
    "            # 那里(logits, loss)返回的logits已经是view过后的形状 (B*T, C)。\n",
    "            # 所以这里logits并不是 (B, T, C)，而是 (B*T, C)\n",
    "            # 如果真的要取每个batch的最后一个时间步的logit，需要先把logits reshape 回 (B, T, C)\n",
    "            B, T = idx.shape\n",
    "            logits = logits.view(B, T, -1)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            # softmax 返回的是所有类别的概率分布，而不是最大概率的索引\n",
    "            # 如果想要最大索引（即贪婪采样），应该用 argmax\n",
    "            # 用 torch.multinomial 是为了从概率分布中按概率随机采样，增加生成多样性\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(loss)\n",
    "print(logits.shape)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45cb3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516d5c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: loss=4.692410945892334\n",
      "step 1: loss=4.664144515991211\n",
      "step 2: loss=4.765714645385742\n",
      "step 3: loss=4.70655632019043\n",
      "step 4: loss=4.5956573486328125\n",
      "step 5: loss=4.7101240158081055\n",
      "step 6: loss=4.713661193847656\n",
      "step 7: loss=4.686909198760986\n",
      "step 8: loss=4.700076103210449\n",
      "step 9: loss=4.718283653259277\n",
      "step 10: loss=4.715603351593018\n",
      "step 11: loss=4.684308052062988\n",
      "step 12: loss=4.745601177215576\n",
      "step 13: loss=4.735717296600342\n",
      "step 14: loss=4.666238784790039\n",
      "step 15: loss=4.58615255355835\n",
      "step 16: loss=4.714625835418701\n",
      "step 17: loss=4.671982765197754\n",
      "step 18: loss=4.715047359466553\n",
      "step 19: loss=4.74489164352417\n",
      "step 20: loss=4.630162715911865\n",
      "step 21: loss=4.707578182220459\n",
      "step 22: loss=4.670665740966797\n",
      "step 23: loss=4.582583427429199\n",
      "step 24: loss=4.739546298980713\n",
      "step 25: loss=4.674807071685791\n",
      "step 26: loss=4.805595874786377\n",
      "step 27: loss=4.749917507171631\n",
      "step 28: loss=4.691989421844482\n",
      "step 29: loss=4.604404926300049\n",
      "step 30: loss=4.721841335296631\n",
      "step 31: loss=4.741591930389404\n",
      "step 32: loss=4.609963417053223\n",
      "step 33: loss=4.662769794464111\n",
      "step 34: loss=4.730099678039551\n",
      "step 35: loss=4.738433361053467\n",
      "step 36: loss=4.688235282897949\n",
      "step 37: loss=4.639987945556641\n",
      "step 38: loss=4.736632823944092\n",
      "step 39: loss=4.709773540496826\n",
      "step 40: loss=4.736939430236816\n",
      "step 41: loss=4.69184684753418\n",
      "step 42: loss=4.719646453857422\n",
      "step 43: loss=4.752516746520996\n",
      "step 44: loss=4.570086479187012\n",
      "step 45: loss=4.643786907196045\n",
      "step 46: loss=4.699163913726807\n",
      "step 47: loss=4.806960105895996\n",
      "step 48: loss=4.572142601013184\n",
      "step 49: loss=4.717066287994385\n",
      "step 50: loss=4.509502410888672\n",
      "step 51: loss=4.603540897369385\n",
      "step 52: loss=4.6649675369262695\n",
      "step 53: loss=4.712099075317383\n",
      "step 54: loss=4.736577033996582\n",
      "step 55: loss=4.812878131866455\n",
      "step 56: loss=4.596436977386475\n",
      "step 57: loss=4.702690601348877\n",
      "step 58: loss=4.711158752441406\n",
      "step 59: loss=4.636075019836426\n",
      "step 60: loss=4.706498146057129\n",
      "step 61: loss=4.706602573394775\n",
      "step 62: loss=4.776336193084717\n",
      "step 63: loss=4.538954257965088\n",
      "step 64: loss=4.595245838165283\n",
      "step 65: loss=4.648927688598633\n",
      "step 66: loss=4.668923854827881\n",
      "step 67: loss=4.5940351486206055\n",
      "step 68: loss=4.757757186889648\n",
      "step 69: loss=4.683036804199219\n",
      "step 70: loss=4.627960205078125\n",
      "step 71: loss=4.809708118438721\n",
      "step 72: loss=4.720103740692139\n",
      "step 73: loss=4.69432258605957\n",
      "step 74: loss=4.593808650970459\n",
      "step 75: loss=4.627923488616943\n",
      "step 76: loss=4.628483772277832\n",
      "step 77: loss=4.594723224639893\n",
      "step 78: loss=4.667132377624512\n",
      "step 79: loss=4.563992500305176\n",
      "step 80: loss=4.598272323608398\n",
      "step 81: loss=4.718154430389404\n",
      "step 82: loss=4.686450958251953\n",
      "step 83: loss=4.564647197723389\n",
      "step 84: loss=4.66386604309082\n",
      "step 85: loss=4.6551690101623535\n",
      "step 86: loss=4.503818511962891\n",
      "step 87: loss=4.662378311157227\n",
      "step 88: loss=4.597469329833984\n",
      "step 89: loss=4.553940773010254\n",
      "step 90: loss=4.6458845138549805\n",
      "step 91: loss=4.658196926116943\n",
      "step 92: loss=4.652643203735352\n",
      "step 93: loss=4.572150230407715\n",
      "step 94: loss=4.654421806335449\n",
      "step 95: loss=4.505650997161865\n",
      "step 96: loss=4.6306376457214355\n",
      "step 97: loss=4.7071919441223145\n",
      "step 98: loss=4.6614508628845215\n",
      "step 99: loss=4.65630578994751\n",
      "step 100: loss=4.621085166931152\n",
      "step 101: loss=4.699936389923096\n",
      "step 102: loss=4.604835510253906\n",
      "step 103: loss=4.62617826461792\n",
      "step 104: loss=4.598467826843262\n",
      "step 105: loss=4.562093257904053\n",
      "step 106: loss=4.61775541305542\n",
      "step 107: loss=4.545349597930908\n",
      "step 108: loss=4.5832133293151855\n",
      "step 109: loss=4.523378849029541\n",
      "step 110: loss=4.568169593811035\n",
      "step 111: loss=4.605664253234863\n",
      "step 112: loss=4.625260829925537\n",
      "step 113: loss=4.56585168838501\n",
      "step 114: loss=4.675260066986084\n",
      "step 115: loss=4.607123851776123\n",
      "step 116: loss=4.707728385925293\n",
      "step 117: loss=4.575418949127197\n",
      "step 118: loss=4.564972877502441\n",
      "step 119: loss=4.588582515716553\n",
      "step 120: loss=4.592921733856201\n",
      "step 121: loss=4.5604448318481445\n",
      "step 122: loss=4.7858452796936035\n",
      "step 123: loss=4.569169521331787\n",
      "step 124: loss=4.5731329917907715\n",
      "step 125: loss=4.601418495178223\n",
      "step 126: loss=4.576107978820801\n",
      "step 127: loss=4.60406494140625\n",
      "step 128: loss=4.595185279846191\n",
      "step 129: loss=4.515230655670166\n",
      "step 130: loss=4.476064205169678\n",
      "step 131: loss=4.521181583404541\n",
      "step 132: loss=4.655724048614502\n",
      "step 133: loss=4.520238399505615\n",
      "step 134: loss=4.546555042266846\n",
      "step 135: loss=4.582464694976807\n",
      "step 136: loss=4.651482105255127\n",
      "step 137: loss=4.5329389572143555\n",
      "step 138: loss=4.552127361297607\n",
      "step 139: loss=4.610964775085449\n",
      "step 140: loss=4.720569610595703\n",
      "step 141: loss=4.532519817352295\n",
      "step 142: loss=4.590734004974365\n",
      "step 143: loss=4.659023284912109\n",
      "step 144: loss=4.569576740264893\n",
      "step 145: loss=4.501828193664551\n",
      "step 146: loss=4.534751892089844\n",
      "step 147: loss=4.5555877685546875\n",
      "step 148: loss=4.437855243682861\n",
      "step 149: loss=4.584807872772217\n",
      "step 150: loss=4.493810176849365\n",
      "step 151: loss=4.496149063110352\n",
      "step 152: loss=4.61268424987793\n",
      "step 153: loss=4.541433811187744\n",
      "step 154: loss=4.462303161621094\n",
      "step 155: loss=4.494714736938477\n",
      "step 156: loss=4.5445098876953125\n",
      "step 157: loss=4.591465473175049\n",
      "step 158: loss=4.559953212738037\n",
      "step 159: loss=4.522037029266357\n",
      "step 160: loss=4.604924201965332\n",
      "step 161: loss=4.505509853363037\n",
      "step 162: loss=4.600823402404785\n",
      "step 163: loss=4.534110069274902\n",
      "step 164: loss=4.466233730316162\n",
      "step 165: loss=4.4869561195373535\n",
      "step 166: loss=4.499792098999023\n",
      "step 167: loss=4.558073043823242\n",
      "step 168: loss=4.6118950843811035\n",
      "step 169: loss=4.532322406768799\n",
      "step 170: loss=4.494655132293701\n",
      "step 171: loss=4.501111030578613\n",
      "step 172: loss=4.487987518310547\n",
      "step 173: loss=4.500681400299072\n",
      "step 174: loss=4.447858810424805\n",
      "step 175: loss=4.551181793212891\n",
      "step 176: loss=4.5280585289001465\n",
      "step 177: loss=4.5666728019714355\n",
      "step 178: loss=4.546204566955566\n",
      "step 179: loss=4.588383197784424\n",
      "step 180: loss=4.5528364181518555\n",
      "step 181: loss=4.483713626861572\n",
      "step 182: loss=4.496376037597656\n",
      "step 183: loss=4.405621528625488\n",
      "step 184: loss=4.482258319854736\n",
      "step 185: loss=4.484110355377197\n",
      "step 186: loss=4.4490227699279785\n",
      "step 187: loss=4.338376045227051\n",
      "step 188: loss=4.460762977600098\n",
      "step 189: loss=4.561094284057617\n",
      "step 190: loss=4.521778583526611\n",
      "step 191: loss=4.64401912689209\n",
      "step 192: loss=4.514046669006348\n",
      "step 193: loss=4.4592413902282715\n",
      "step 194: loss=4.4573655128479\n",
      "step 195: loss=4.652929782867432\n",
      "step 196: loss=4.569197177886963\n",
      "step 197: loss=4.549731254577637\n",
      "step 198: loss=4.605109691619873\n",
      "step 199: loss=4.531443119049072\n",
      "step 200: loss=4.549462795257568\n",
      "step 201: loss=4.4532389640808105\n",
      "step 202: loss=4.42667293548584\n",
      "step 203: loss=4.428462505340576\n",
      "step 204: loss=4.5073981285095215\n",
      "step 205: loss=4.599745273590088\n",
      "step 206: loss=4.428247451782227\n",
      "step 207: loss=4.516406059265137\n",
      "step 208: loss=4.531017780303955\n",
      "step 209: loss=4.524899005889893\n",
      "step 210: loss=4.43112325668335\n",
      "step 211: loss=4.413572311401367\n",
      "step 212: loss=4.460278511047363\n",
      "step 213: loss=4.394894123077393\n",
      "step 214: loss=4.440585136413574\n",
      "step 215: loss=4.515986442565918\n",
      "step 216: loss=4.501888751983643\n",
      "step 217: loss=4.540366172790527\n",
      "step 218: loss=4.476080417633057\n",
      "step 219: loss=4.480386257171631\n",
      "step 220: loss=4.420384407043457\n",
      "step 221: loss=4.483820915222168\n",
      "step 222: loss=4.512678146362305\n",
      "step 223: loss=4.560887336730957\n",
      "step 224: loss=4.491804599761963\n",
      "step 225: loss=4.480713844299316\n",
      "step 226: loss=4.423666954040527\n",
      "step 227: loss=4.433342456817627\n",
      "step 228: loss=4.417287826538086\n",
      "step 229: loss=4.414680480957031\n",
      "step 230: loss=4.418458461761475\n",
      "step 231: loss=4.457849025726318\n",
      "step 232: loss=4.501733779907227\n",
      "step 233: loss=4.55715799331665\n",
      "step 234: loss=4.420411109924316\n",
      "step 235: loss=4.500718116760254\n",
      "step 236: loss=4.4469828605651855\n",
      "step 237: loss=4.404678821563721\n",
      "step 238: loss=4.448772430419922\n",
      "step 239: loss=4.48320198059082\n",
      "step 240: loss=4.401884078979492\n",
      "step 241: loss=4.445903301239014\n",
      "step 242: loss=4.52253532409668\n",
      "step 243: loss=4.410618305206299\n",
      "step 244: loss=4.45168924331665\n",
      "step 245: loss=4.405672073364258\n",
      "step 246: loss=4.359124660491943\n",
      "step 247: loss=4.418424606323242\n",
      "step 248: loss=4.447394371032715\n",
      "step 249: loss=4.4999918937683105\n",
      "step 250: loss=4.495026111602783\n",
      "step 251: loss=4.441216945648193\n",
      "step 252: loss=4.3983259201049805\n",
      "step 253: loss=4.399979591369629\n",
      "step 254: loss=4.396550178527832\n",
      "step 255: loss=4.515158176422119\n",
      "step 256: loss=4.436650276184082\n",
      "step 257: loss=4.254152774810791\n",
      "step 258: loss=4.4689860343933105\n",
      "step 259: loss=4.4714837074279785\n",
      "step 260: loss=4.331572532653809\n",
      "step 261: loss=4.43186616897583\n",
      "step 262: loss=4.361902713775635\n",
      "step 263: loss=4.399670124053955\n",
      "step 264: loss=4.441038608551025\n",
      "step 265: loss=4.391478061676025\n",
      "step 266: loss=4.487184524536133\n",
      "step 267: loss=4.294976234436035\n",
      "step 268: loss=4.41543436050415\n",
      "step 269: loss=4.420255661010742\n",
      "step 270: loss=4.351208209991455\n",
      "step 271: loss=4.358051300048828\n",
      "step 272: loss=4.529325008392334\n",
      "step 273: loss=4.34090518951416\n",
      "step 274: loss=4.488083839416504\n",
      "step 275: loss=4.442676067352295\n",
      "step 276: loss=4.422273635864258\n",
      "step 277: loss=4.372884273529053\n",
      "step 278: loss=4.420283317565918\n",
      "step 279: loss=4.343837261199951\n",
      "step 280: loss=4.380279064178467\n",
      "step 281: loss=4.460439205169678\n",
      "step 282: loss=4.4696574211120605\n",
      "step 283: loss=4.4250054359436035\n",
      "step 284: loss=4.369536876678467\n",
      "step 285: loss=4.380033016204834\n",
      "step 286: loss=4.365662097930908\n",
      "step 287: loss=4.339999675750732\n",
      "step 288: loss=4.48419713973999\n",
      "step 289: loss=4.555813789367676\n",
      "step 290: loss=4.4380035400390625\n",
      "step 291: loss=4.477532386779785\n",
      "step 292: loss=4.378237724304199\n",
      "step 293: loss=4.336991310119629\n",
      "step 294: loss=4.448875427246094\n",
      "step 295: loss=4.361961841583252\n",
      "step 296: loss=4.365668296813965\n",
      "step 297: loss=4.469748020172119\n",
      "step 298: loss=4.392701625823975\n",
      "step 299: loss=4.334584712982178\n",
      "step 300: loss=4.345612049102783\n",
      "step 301: loss=4.306689739227295\n",
      "step 302: loss=4.438986301422119\n",
      "step 303: loss=4.454972267150879\n",
      "step 304: loss=4.497693061828613\n",
      "step 305: loss=4.392993927001953\n",
      "step 306: loss=4.369708061218262\n",
      "step 307: loss=4.354208469390869\n",
      "step 308: loss=4.376923084259033\n",
      "step 309: loss=4.388126850128174\n",
      "step 310: loss=4.346914291381836\n",
      "step 311: loss=4.454780101776123\n",
      "step 312: loss=4.369599342346191\n",
      "step 313: loss=4.400058746337891\n",
      "step 314: loss=4.321812629699707\n",
      "step 315: loss=4.430188179016113\n",
      "step 316: loss=4.363119125366211\n",
      "step 317: loss=4.258288860321045\n",
      "step 318: loss=4.324169635772705\n",
      "step 319: loss=4.358462333679199\n",
      "step 320: loss=4.358053207397461\n",
      "step 321: loss=4.346726417541504\n",
      "step 322: loss=4.4252777099609375\n",
      "step 323: loss=4.3356428146362305\n",
      "step 324: loss=4.356608867645264\n",
      "step 325: loss=4.268974304199219\n",
      "step 326: loss=4.34548282623291\n",
      "step 327: loss=4.391635894775391\n",
      "step 328: loss=4.350566387176514\n",
      "step 329: loss=4.366872310638428\n",
      "step 330: loss=4.406307220458984\n",
      "step 331: loss=4.266676425933838\n",
      "step 332: loss=4.258195877075195\n",
      "step 333: loss=4.2933526039123535\n",
      "step 334: loss=4.3209686279296875\n",
      "step 335: loss=4.332687854766846\n",
      "step 336: loss=4.352051258087158\n",
      "step 337: loss=4.382238864898682\n",
      "step 338: loss=4.383143901824951\n",
      "step 339: loss=4.244317531585693\n",
      "step 340: loss=4.3100972175598145\n",
      "step 341: loss=4.301767826080322\n",
      "step 342: loss=4.462956428527832\n",
      "step 343: loss=4.325232028961182\n",
      "step 344: loss=4.341349124908447\n",
      "step 345: loss=4.296145439147949\n",
      "step 346: loss=4.235404014587402\n",
      "step 347: loss=4.250915050506592\n",
      "step 348: loss=4.308598518371582\n",
      "step 349: loss=4.376663684844971\n",
      "step 350: loss=4.237582683563232\n",
      "step 351: loss=4.350257396697998\n",
      "step 352: loss=4.228846549987793\n",
      "step 353: loss=4.305774211883545\n",
      "step 354: loss=4.354750633239746\n",
      "step 355: loss=4.467280864715576\n",
      "step 356: loss=4.318342685699463\n",
      "step 357: loss=4.338566780090332\n",
      "step 358: loss=4.289865970611572\n",
      "step 359: loss=4.2690815925598145\n",
      "step 360: loss=4.180973529815674\n",
      "step 361: loss=4.387163162231445\n",
      "step 362: loss=4.275718688964844\n",
      "step 363: loss=4.193756580352783\n",
      "step 364: loss=4.348846435546875\n",
      "step 365: loss=4.311291694641113\n",
      "step 366: loss=4.2306294441223145\n",
      "step 367: loss=4.389198303222656\n",
      "step 368: loss=4.380277633666992\n",
      "step 369: loss=4.376614570617676\n",
      "step 370: loss=4.3441596031188965\n",
      "step 371: loss=4.27800989151001\n",
      "step 372: loss=4.265659332275391\n",
      "step 373: loss=4.27650260925293\n",
      "step 374: loss=4.285951614379883\n",
      "step 375: loss=4.260744094848633\n",
      "step 376: loss=4.254425525665283\n",
      "step 377: loss=4.387601852416992\n",
      "step 378: loss=4.293213367462158\n",
      "step 379: loss=4.275619029998779\n",
      "step 380: loss=4.264163017272949\n",
      "step 381: loss=4.214735507965088\n",
      "step 382: loss=4.323124885559082\n",
      "step 383: loss=4.272207260131836\n",
      "step 384: loss=4.2730560302734375\n",
      "step 385: loss=4.332861423492432\n",
      "step 386: loss=4.228231906890869\n",
      "step 387: loss=4.272346496582031\n",
      "step 388: loss=4.331362724304199\n",
      "step 389: loss=4.377825736999512\n",
      "step 390: loss=4.194937705993652\n",
      "step 391: loss=4.29219913482666\n",
      "step 392: loss=4.230798244476318\n",
      "step 393: loss=4.251380920410156\n",
      "step 394: loss=4.296419620513916\n",
      "step 395: loss=4.252346992492676\n",
      "step 396: loss=4.2831315994262695\n",
      "step 397: loss=4.3855204582214355\n",
      "step 398: loss=4.1769537925720215\n",
      "step 399: loss=4.227319717407227\n",
      "step 400: loss=4.25573205947876\n",
      "step 401: loss=4.238279819488525\n",
      "step 402: loss=4.283568382263184\n",
      "step 403: loss=4.299123764038086\n",
      "step 404: loss=4.25726318359375\n",
      "step 405: loss=4.330580711364746\n",
      "step 406: loss=4.313518524169922\n",
      "step 407: loss=4.335666179656982\n",
      "step 408: loss=4.248019695281982\n",
      "step 409: loss=4.212539196014404\n",
      "step 410: loss=4.390359878540039\n",
      "step 411: loss=4.26472806930542\n",
      "step 412: loss=4.235801696777344\n",
      "step 413: loss=4.21953821182251\n",
      "step 414: loss=4.3849310874938965\n",
      "step 415: loss=4.191295146942139\n",
      "step 416: loss=4.29976224899292\n",
      "step 417: loss=4.263235092163086\n",
      "step 418: loss=4.209293365478516\n",
      "step 419: loss=4.223510265350342\n",
      "step 420: loss=4.197415351867676\n",
      "step 421: loss=4.352291584014893\n",
      "step 422: loss=4.358164310455322\n",
      "step 423: loss=4.247671604156494\n",
      "step 424: loss=4.329915523529053\n",
      "step 425: loss=4.220633506774902\n",
      "step 426: loss=4.240585803985596\n",
      "step 427: loss=4.314285755157471\n",
      "step 428: loss=4.2603759765625\n",
      "step 429: loss=4.259975433349609\n",
      "step 430: loss=4.2319464683532715\n",
      "step 431: loss=4.184201240539551\n",
      "step 432: loss=4.277885913848877\n",
      "step 433: loss=4.279393196105957\n",
      "step 434: loss=4.180922508239746\n",
      "step 435: loss=4.270190238952637\n",
      "step 436: loss=4.253904819488525\n",
      "step 437: loss=4.179213047027588\n",
      "step 438: loss=4.2253098487854\n",
      "step 439: loss=4.279184341430664\n",
      "step 440: loss=4.301351547241211\n",
      "step 441: loss=4.229222297668457\n",
      "step 442: loss=4.343070030212402\n",
      "step 443: loss=4.276855945587158\n",
      "step 444: loss=4.191099166870117\n",
      "step 445: loss=4.293545722961426\n",
      "step 446: loss=4.201022148132324\n",
      "step 447: loss=4.206254959106445\n",
      "step 448: loss=4.195919990539551\n",
      "step 449: loss=4.2168192863464355\n",
      "step 450: loss=4.221164703369141\n",
      "step 451: loss=4.163954257965088\n",
      "step 452: loss=4.355230331420898\n",
      "step 453: loss=4.183740139007568\n",
      "step 454: loss=4.180234432220459\n",
      "step 455: loss=4.350985050201416\n",
      "step 456: loss=4.179173946380615\n",
      "step 457: loss=4.266575336456299\n",
      "step 458: loss=4.145872592926025\n",
      "step 459: loss=4.3596954345703125\n",
      "step 460: loss=4.116206169128418\n",
      "step 461: loss=4.278004169464111\n",
      "step 462: loss=4.263311386108398\n",
      "step 463: loss=4.26434850692749\n",
      "step 464: loss=4.247138977050781\n",
      "step 465: loss=4.2241597175598145\n",
      "step 466: loss=4.163585662841797\n",
      "step 467: loss=4.185435771942139\n",
      "step 468: loss=4.255035877227783\n",
      "step 469: loss=4.19374418258667\n",
      "step 470: loss=4.256316661834717\n",
      "step 471: loss=4.281538963317871\n",
      "step 472: loss=4.171205043792725\n",
      "step 473: loss=4.182270526885986\n",
      "step 474: loss=4.194500923156738\n",
      "step 475: loss=4.283398628234863\n",
      "step 476: loss=4.299307823181152\n",
      "step 477: loss=4.241708755493164\n",
      "step 478: loss=4.283669948577881\n",
      "step 479: loss=4.143308639526367\n",
      "step 480: loss=4.15635347366333\n",
      "step 481: loss=4.232965469360352\n",
      "step 482: loss=4.241590976715088\n",
      "step 483: loss=4.03627872467041\n",
      "step 484: loss=4.157522201538086\n",
      "step 485: loss=4.231443405151367\n",
      "step 486: loss=4.147864818572998\n",
      "step 487: loss=4.156970024108887\n",
      "step 488: loss=4.223931789398193\n",
      "step 489: loss=4.105999946594238\n",
      "step 490: loss=4.140515327453613\n",
      "step 491: loss=4.220064163208008\n",
      "step 492: loss=4.173741817474365\n",
      "step 493: loss=4.072698593139648\n",
      "step 494: loss=4.158931255340576\n",
      "step 495: loss=4.1450676918029785\n",
      "step 496: loss=4.184323787689209\n",
      "step 497: loss=4.103063583374023\n",
      "step 498: loss=4.092406272888184\n",
      "step 499: loss=4.1035356521606445\n",
      "step 500: loss=4.214480876922607\n",
      "step 501: loss=4.084356307983398\n",
      "step 502: loss=4.133087158203125\n",
      "step 503: loss=4.223405838012695\n",
      "step 504: loss=4.220446586608887\n",
      "step 505: loss=4.17624568939209\n",
      "step 506: loss=4.128087043762207\n",
      "step 507: loss=4.1905412673950195\n",
      "step 508: loss=4.2345123291015625\n",
      "step 509: loss=4.164053440093994\n",
      "step 510: loss=4.095093250274658\n",
      "step 511: loss=4.139039039611816\n",
      "step 512: loss=4.137739181518555\n",
      "step 513: loss=4.16702127456665\n",
      "step 514: loss=4.160588264465332\n",
      "step 515: loss=4.111112594604492\n",
      "step 516: loss=4.019512176513672\n",
      "step 517: loss=4.21013879776001\n",
      "step 518: loss=4.071273326873779\n",
      "step 519: loss=4.1922783851623535\n",
      "step 520: loss=4.240005016326904\n",
      "step 521: loss=4.245697021484375\n",
      "step 522: loss=4.147686958312988\n",
      "step 523: loss=4.2053656578063965\n",
      "step 524: loss=4.214274883270264\n",
      "step 525: loss=4.0432515144348145\n",
      "step 526: loss=4.149839401245117\n",
      "step 527: loss=4.167660713195801\n",
      "step 528: loss=4.0837626457214355\n",
      "step 529: loss=4.21851110458374\n",
      "step 530: loss=4.211829662322998\n",
      "step 531: loss=4.033554553985596\n",
      "step 532: loss=4.161428928375244\n",
      "step 533: loss=4.165452003479004\n",
      "step 534: loss=4.050341606140137\n",
      "step 535: loss=4.1566925048828125\n",
      "step 536: loss=4.160954475402832\n",
      "step 537: loss=4.093878269195557\n",
      "step 538: loss=4.132650375366211\n",
      "step 539: loss=4.1404008865356445\n",
      "step 540: loss=4.130082130432129\n",
      "step 541: loss=4.175171375274658\n",
      "step 542: loss=4.112301826477051\n",
      "step 543: loss=4.073479175567627\n",
      "step 544: loss=4.167318820953369\n",
      "step 545: loss=4.1959919929504395\n",
      "step 546: loss=4.078147888183594\n",
      "step 547: loss=4.069385528564453\n",
      "step 548: loss=4.063492774963379\n",
      "step 549: loss=4.158783435821533\n",
      "step 550: loss=4.046174049377441\n",
      "step 551: loss=4.117081642150879\n",
      "step 552: loss=4.2450761795043945\n",
      "step 553: loss=4.109870433807373\n",
      "step 554: loss=4.118143081665039\n",
      "step 555: loss=4.16467809677124\n",
      "step 556: loss=4.108386039733887\n",
      "step 557: loss=4.165163040161133\n",
      "step 558: loss=4.048225402832031\n",
      "step 559: loss=4.135279655456543\n",
      "step 560: loss=4.158371925354004\n",
      "step 561: loss=4.126312732696533\n",
      "step 562: loss=3.964298725128174\n",
      "step 563: loss=4.15919303894043\n",
      "step 564: loss=4.119665145874023\n",
      "step 565: loss=4.238160133361816\n",
      "step 566: loss=4.114436626434326\n",
      "step 567: loss=4.085212230682373\n",
      "step 568: loss=4.048520088195801\n",
      "step 569: loss=4.12908411026001\n",
      "step 570: loss=4.118659019470215\n",
      "step 571: loss=4.099023818969727\n",
      "step 572: loss=4.183162689208984\n",
      "step 573: loss=4.058305740356445\n",
      "step 574: loss=4.143056392669678\n",
      "step 575: loss=4.114629745483398\n",
      "step 576: loss=4.0972514152526855\n",
      "step 577: loss=4.099020481109619\n",
      "step 578: loss=4.109713554382324\n",
      "step 579: loss=4.0857157707214355\n",
      "step 580: loss=4.125316143035889\n",
      "step 581: loss=4.175577640533447\n",
      "step 582: loss=4.063840389251709\n",
      "step 583: loss=4.108927249908447\n",
      "step 584: loss=4.104191780090332\n",
      "step 585: loss=4.119007110595703\n",
      "step 586: loss=4.09041166305542\n",
      "step 587: loss=4.067192077636719\n",
      "step 588: loss=4.102412223815918\n",
      "step 589: loss=4.113567352294922\n",
      "step 590: loss=4.192253589630127\n",
      "step 591: loss=4.100231170654297\n",
      "step 592: loss=4.120125770568848\n",
      "step 593: loss=4.143221378326416\n",
      "step 594: loss=4.08186674118042\n",
      "step 595: loss=4.087782382965088\n",
      "step 596: loss=4.074817657470703\n",
      "step 597: loss=4.0610480308532715\n",
      "step 598: loss=4.183136463165283\n",
      "step 599: loss=4.0359954833984375\n",
      "step 600: loss=4.124096870422363\n",
      "step 601: loss=4.125418186187744\n",
      "step 602: loss=4.087498188018799\n",
      "step 603: loss=4.018767356872559\n",
      "step 604: loss=4.111219882965088\n",
      "step 605: loss=4.014806270599365\n",
      "step 606: loss=4.001387596130371\n",
      "step 607: loss=3.984426736831665\n",
      "step 608: loss=4.148003578186035\n",
      "step 609: loss=4.025826454162598\n",
      "step 610: loss=4.057998180389404\n",
      "step 611: loss=3.9568910598754883\n",
      "step 612: loss=4.0929460525512695\n",
      "step 613: loss=4.072330474853516\n",
      "step 614: loss=4.03060245513916\n",
      "step 615: loss=4.048306941986084\n",
      "step 616: loss=4.133228778839111\n",
      "step 617: loss=4.038397789001465\n",
      "step 618: loss=4.125432014465332\n",
      "step 619: loss=4.072927474975586\n",
      "step 620: loss=4.045656204223633\n",
      "step 621: loss=4.1224045753479\n",
      "step 622: loss=4.121188163757324\n",
      "step 623: loss=4.098836898803711\n",
      "step 624: loss=4.161966323852539\n",
      "step 625: loss=4.04520845413208\n",
      "step 626: loss=4.056055068969727\n",
      "step 627: loss=3.9817774295806885\n",
      "step 628: loss=4.114030361175537\n",
      "step 629: loss=4.055196762084961\n",
      "step 630: loss=4.181158065795898\n",
      "step 631: loss=4.015369415283203\n",
      "step 632: loss=4.070910453796387\n",
      "step 633: loss=4.0655999183654785\n",
      "step 634: loss=4.0205183029174805\n",
      "step 635: loss=4.009420871734619\n",
      "step 636: loss=4.009321689605713\n",
      "step 637: loss=4.121938705444336\n",
      "step 638: loss=4.040282726287842\n",
      "step 639: loss=4.006514072418213\n",
      "step 640: loss=3.9769175052642822\n",
      "step 641: loss=3.9687490463256836\n",
      "step 642: loss=4.053492546081543\n",
      "step 643: loss=4.024524211883545\n",
      "step 644: loss=4.1228790283203125\n",
      "step 645: loss=3.9823174476623535\n",
      "step 646: loss=3.9732022285461426\n",
      "step 647: loss=4.015324592590332\n",
      "step 648: loss=4.0347113609313965\n",
      "step 649: loss=4.076888561248779\n",
      "step 650: loss=4.0141777992248535\n",
      "step 651: loss=4.0707106590271\n",
      "step 652: loss=4.029590606689453\n",
      "step 653: loss=4.0675764083862305\n",
      "step 654: loss=3.958583116531372\n",
      "step 655: loss=4.049327850341797\n",
      "step 656: loss=3.9634346961975098\n",
      "step 657: loss=4.109421730041504\n",
      "step 658: loss=4.038191795349121\n",
      "step 659: loss=4.125021934509277\n",
      "step 660: loss=4.031307220458984\n",
      "step 661: loss=4.070112705230713\n",
      "step 662: loss=3.9946374893188477\n",
      "step 663: loss=4.0985188484191895\n",
      "step 664: loss=3.9959030151367188\n",
      "step 665: loss=4.035952568054199\n",
      "step 666: loss=4.017228603363037\n",
      "step 667: loss=4.024997234344482\n",
      "step 668: loss=3.9557952880859375\n",
      "step 669: loss=4.03995418548584\n",
      "step 670: loss=4.067239761352539\n",
      "step 671: loss=4.015563011169434\n",
      "step 672: loss=4.054080486297607\n",
      "step 673: loss=4.0563883781433105\n",
      "step 674: loss=3.9339613914489746\n",
      "step 675: loss=3.991907835006714\n",
      "step 676: loss=3.9665045738220215\n",
      "step 677: loss=4.003228664398193\n",
      "step 678: loss=4.0467000007629395\n",
      "step 679: loss=4.060911178588867\n",
      "step 680: loss=3.9072952270507812\n",
      "step 681: loss=4.017505645751953\n",
      "step 682: loss=4.071604251861572\n",
      "step 683: loss=4.083905220031738\n",
      "step 684: loss=4.046928405761719\n",
      "step 685: loss=4.020439624786377\n",
      "step 686: loss=3.9562582969665527\n",
      "step 687: loss=3.857187509536743\n",
      "step 688: loss=3.9379940032958984\n",
      "step 689: loss=4.030976295471191\n",
      "step 690: loss=4.080989837646484\n",
      "step 691: loss=3.94681715965271\n",
      "step 692: loss=4.019579887390137\n",
      "step 693: loss=3.9735379219055176\n",
      "step 694: loss=4.019238471984863\n",
      "step 695: loss=4.019179344177246\n",
      "step 696: loss=3.9712741374969482\n",
      "step 697: loss=4.026883602142334\n",
      "step 698: loss=4.021551609039307\n",
      "step 699: loss=4.090793132781982\n",
      "step 700: loss=3.9863951206207275\n",
      "step 701: loss=4.023050308227539\n",
      "step 702: loss=3.958601474761963\n",
      "step 703: loss=3.948957681655884\n",
      "step 704: loss=3.9391560554504395\n",
      "step 705: loss=3.979315996170044\n",
      "step 706: loss=4.014042854309082\n",
      "step 707: loss=3.987943410873413\n",
      "step 708: loss=4.037786483764648\n",
      "step 709: loss=3.9132330417633057\n",
      "step 710: loss=3.93660569190979\n",
      "step 711: loss=3.9861817359924316\n",
      "step 712: loss=3.9920737743377686\n",
      "step 713: loss=3.935559034347534\n",
      "step 714: loss=4.01882791519165\n",
      "step 715: loss=3.9929792881011963\n",
      "step 716: loss=3.959758758544922\n",
      "step 717: loss=3.9396843910217285\n",
      "step 718: loss=4.044256687164307\n",
      "step 719: loss=4.004631996154785\n",
      "step 720: loss=3.996853828430176\n",
      "step 721: loss=4.005602836608887\n",
      "step 722: loss=4.0114874839782715\n",
      "step 723: loss=3.909653663635254\n",
      "step 724: loss=3.9997363090515137\n",
      "step 725: loss=4.052602291107178\n",
      "step 726: loss=3.982553720474243\n",
      "step 727: loss=3.9164369106292725\n",
      "step 728: loss=3.942601203918457\n",
      "step 729: loss=3.9261810779571533\n",
      "step 730: loss=3.895392894744873\n",
      "step 731: loss=3.9324474334716797\n",
      "step 732: loss=3.9205896854400635\n",
      "step 733: loss=3.862194061279297\n",
      "step 734: loss=3.914445400238037\n",
      "step 735: loss=3.8829867839813232\n",
      "step 736: loss=3.958883047103882\n",
      "step 737: loss=3.985666036605835\n",
      "step 738: loss=3.899744987487793\n",
      "step 739: loss=3.9055404663085938\n",
      "step 740: loss=3.9618642330169678\n",
      "step 741: loss=3.889052391052246\n",
      "step 742: loss=3.9750149250030518\n",
      "step 743: loss=3.955091953277588\n",
      "step 744: loss=3.9291818141937256\n",
      "step 745: loss=4.087095737457275\n",
      "step 746: loss=3.9071226119995117\n",
      "step 747: loss=3.909717082977295\n",
      "step 748: loss=3.9263739585876465\n",
      "step 749: loss=3.936264991760254\n",
      "step 750: loss=3.9365665912628174\n",
      "step 751: loss=3.938066005706787\n",
      "step 752: loss=3.970029830932617\n",
      "step 753: loss=3.9482243061065674\n",
      "step 754: loss=3.8840718269348145\n",
      "step 755: loss=3.952329635620117\n",
      "step 756: loss=3.8996760845184326\n",
      "step 757: loss=3.868910789489746\n",
      "step 758: loss=3.926823377609253\n",
      "step 759: loss=3.8954102993011475\n",
      "step 760: loss=4.0050368309021\n",
      "step 761: loss=3.949986696243286\n",
      "step 762: loss=3.946974277496338\n",
      "step 763: loss=3.8552606105804443\n",
      "step 764: loss=4.010585784912109\n",
      "step 765: loss=4.076684951782227\n",
      "step 766: loss=3.9837636947631836\n",
      "step 767: loss=3.980055332183838\n",
      "step 768: loss=4.009552478790283\n",
      "step 769: loss=3.981788158416748\n",
      "step 770: loss=3.9590961933135986\n",
      "step 771: loss=3.8400533199310303\n",
      "step 772: loss=3.88386607170105\n",
      "step 773: loss=3.8691532611846924\n",
      "step 774: loss=3.783965826034546\n",
      "step 775: loss=3.9049429893493652\n",
      "step 776: loss=3.9803521633148193\n",
      "step 777: loss=3.9815800189971924\n",
      "step 778: loss=3.8576600551605225\n",
      "step 779: loss=3.8969061374664307\n",
      "step 780: loss=3.9168310165405273\n",
      "step 781: loss=3.8810322284698486\n",
      "step 782: loss=3.8791961669921875\n",
      "step 783: loss=3.9240477085113525\n",
      "step 784: loss=3.853982448577881\n",
      "step 785: loss=3.9570164680480957\n",
      "step 786: loss=3.8988611698150635\n",
      "step 787: loss=3.906435251235962\n",
      "step 788: loss=3.8281397819519043\n",
      "step 789: loss=3.8748936653137207\n",
      "step 790: loss=3.7957098484039307\n",
      "step 791: loss=3.88936185836792\n",
      "step 792: loss=3.8909873962402344\n",
      "step 793: loss=3.9083378314971924\n",
      "step 794: loss=3.9673893451690674\n",
      "step 795: loss=3.7797911167144775\n",
      "step 796: loss=3.875593900680542\n",
      "step 797: loss=3.9253997802734375\n",
      "step 798: loss=3.9070682525634766\n",
      "step 799: loss=3.947261333465576\n",
      "step 800: loss=3.9517807960510254\n",
      "step 801: loss=3.9063897132873535\n",
      "step 802: loss=3.9117953777313232\n",
      "step 803: loss=3.870689630508423\n",
      "step 804: loss=3.8529112339019775\n",
      "step 805: loss=3.899077892303467\n",
      "step 806: loss=3.8730580806732178\n",
      "step 807: loss=3.8374412059783936\n",
      "step 808: loss=3.9627768993377686\n",
      "step 809: loss=3.8845608234405518\n",
      "step 810: loss=3.8707284927368164\n",
      "step 811: loss=3.812702178955078\n",
      "step 812: loss=3.9962551593780518\n",
      "step 813: loss=3.9128105640411377\n",
      "step 814: loss=3.903803825378418\n",
      "step 815: loss=3.901273012161255\n",
      "step 816: loss=3.8220882415771484\n",
      "step 817: loss=3.8226215839385986\n",
      "step 818: loss=3.8852691650390625\n",
      "step 819: loss=3.82008957862854\n",
      "step 820: loss=3.8163669109344482\n",
      "step 821: loss=3.7907116413116455\n",
      "step 822: loss=3.8253843784332275\n",
      "step 823: loss=3.8396363258361816\n",
      "step 824: loss=3.8457422256469727\n",
      "step 825: loss=3.8769731521606445\n",
      "step 826: loss=3.8439457416534424\n",
      "step 827: loss=3.876339912414551\n",
      "step 828: loss=3.908766746520996\n",
      "step 829: loss=3.8244807720184326\n",
      "step 830: loss=3.840985059738159\n",
      "step 831: loss=3.755624294281006\n",
      "step 832: loss=3.857574939727783\n",
      "step 833: loss=3.9703409671783447\n",
      "step 834: loss=3.698105812072754\n",
      "step 835: loss=3.7928614616394043\n",
      "step 836: loss=3.8883657455444336\n",
      "step 837: loss=3.9447708129882812\n",
      "step 838: loss=3.814781665802002\n",
      "step 839: loss=3.8951287269592285\n",
      "step 840: loss=3.802658796310425\n",
      "step 841: loss=3.8546926975250244\n",
      "step 842: loss=3.90655255317688\n",
      "step 843: loss=3.7954976558685303\n",
      "step 844: loss=3.80258846282959\n",
      "step 845: loss=3.848461389541626\n",
      "step 846: loss=3.8054921627044678\n",
      "step 847: loss=3.831833839416504\n",
      "step 848: loss=3.858421564102173\n",
      "step 849: loss=3.7204763889312744\n",
      "step 850: loss=3.9306366443634033\n",
      "step 851: loss=3.8283700942993164\n",
      "step 852: loss=3.828134775161743\n",
      "step 853: loss=3.854487895965576\n",
      "step 854: loss=3.8038671016693115\n",
      "step 855: loss=3.739840030670166\n",
      "step 856: loss=3.8414194583892822\n",
      "step 857: loss=3.840139627456665\n",
      "step 858: loss=3.858626365661621\n",
      "step 859: loss=3.8682193756103516\n",
      "step 860: loss=3.7725791931152344\n",
      "step 861: loss=3.7404379844665527\n",
      "step 862: loss=3.853250503540039\n",
      "step 863: loss=3.909426212310791\n",
      "step 864: loss=3.827120304107666\n",
      "step 865: loss=3.9142749309539795\n",
      "step 866: loss=3.8566269874572754\n",
      "step 867: loss=3.836930990219116\n",
      "step 868: loss=3.8507373332977295\n",
      "step 869: loss=3.7641050815582275\n",
      "step 870: loss=3.8466036319732666\n",
      "step 871: loss=3.8550658226013184\n",
      "step 872: loss=3.814547538757324\n",
      "step 873: loss=3.858736515045166\n",
      "step 874: loss=3.835547924041748\n",
      "step 875: loss=3.820634126663208\n",
      "step 876: loss=3.8446009159088135\n",
      "step 877: loss=3.8565011024475098\n",
      "step 878: loss=3.793048858642578\n",
      "step 879: loss=3.803140640258789\n",
      "step 880: loss=3.877279281616211\n",
      "step 881: loss=3.915501356124878\n",
      "step 882: loss=3.737924098968506\n",
      "step 883: loss=3.7830746173858643\n",
      "step 884: loss=3.773716926574707\n",
      "step 885: loss=3.769728660583496\n",
      "step 886: loss=3.76853084564209\n",
      "step 887: loss=3.774484395980835\n",
      "step 888: loss=3.908461093902588\n",
      "step 889: loss=3.785860300064087\n",
      "step 890: loss=3.840094804763794\n",
      "step 891: loss=3.9154365062713623\n",
      "step 892: loss=3.7070677280426025\n",
      "step 893: loss=3.876446485519409\n",
      "step 894: loss=3.8132681846618652\n",
      "step 895: loss=3.7787420749664307\n",
      "step 896: loss=3.808058023452759\n",
      "step 897: loss=3.7111711502075195\n",
      "step 898: loss=3.7674307823181152\n",
      "step 899: loss=3.886543035507202\n",
      "step 900: loss=3.837888717651367\n",
      "step 901: loss=3.7464873790740967\n",
      "step 902: loss=3.8434603214263916\n",
      "step 903: loss=3.8652989864349365\n",
      "step 904: loss=3.9370501041412354\n",
      "step 905: loss=3.7554266452789307\n",
      "step 906: loss=3.80645751953125\n",
      "step 907: loss=3.7218282222747803\n",
      "step 908: loss=3.841688394546509\n",
      "step 909: loss=3.838592529296875\n",
      "step 910: loss=3.7659902572631836\n",
      "step 911: loss=3.8026273250579834\n",
      "step 912: loss=3.730456829071045\n",
      "step 913: loss=3.7594165802001953\n",
      "step 914: loss=3.868187189102173\n",
      "step 915: loss=3.8208365440368652\n",
      "step 916: loss=3.8494954109191895\n",
      "step 917: loss=3.6943864822387695\n",
      "step 918: loss=3.825169324874878\n",
      "step 919: loss=3.802319049835205\n",
      "step 920: loss=3.7781949043273926\n",
      "step 921: loss=3.8065850734710693\n",
      "step 922: loss=3.795403003692627\n",
      "step 923: loss=3.826564311981201\n",
      "step 924: loss=3.7271037101745605\n",
      "step 925: loss=3.769099473953247\n",
      "step 926: loss=3.814549684524536\n",
      "step 927: loss=3.7501776218414307\n",
      "step 928: loss=3.8552398681640625\n",
      "step 929: loss=3.7635231018066406\n",
      "step 930: loss=3.757671594619751\n",
      "step 931: loss=3.7829813957214355\n",
      "step 932: loss=3.856001377105713\n",
      "step 933: loss=3.786350965499878\n",
      "step 934: loss=3.7992660999298096\n",
      "step 935: loss=3.853888511657715\n",
      "step 936: loss=3.7279489040374756\n",
      "step 937: loss=3.77148699760437\n",
      "step 938: loss=3.6774191856384277\n",
      "step 939: loss=3.7062580585479736\n",
      "step 940: loss=3.8540217876434326\n",
      "step 941: loss=3.714585065841675\n",
      "step 942: loss=3.75681209564209\n",
      "step 943: loss=3.8052268028259277\n",
      "step 944: loss=3.750840425491333\n",
      "step 945: loss=3.7266221046447754\n",
      "step 946: loss=3.8073298931121826\n",
      "step 947: loss=3.621952772140503\n",
      "step 948: loss=3.7910683155059814\n",
      "step 949: loss=3.783512830734253\n",
      "step 950: loss=3.916217088699341\n",
      "step 951: loss=3.8640291690826416\n",
      "step 952: loss=3.75536847114563\n",
      "step 953: loss=3.7300283908843994\n",
      "step 954: loss=3.797163963317871\n",
      "step 955: loss=3.7928595542907715\n",
      "step 956: loss=3.7810394763946533\n",
      "step 957: loss=3.8614728450775146\n",
      "step 958: loss=3.801198720932007\n",
      "step 959: loss=3.831483840942383\n",
      "step 960: loss=3.7052838802337646\n",
      "step 961: loss=3.786813735961914\n",
      "step 962: loss=3.731647253036499\n",
      "step 963: loss=3.7757680416107178\n",
      "step 964: loss=3.7474052906036377\n",
      "step 965: loss=3.761415481567383\n",
      "step 966: loss=3.806239128112793\n",
      "step 967: loss=3.7878215312957764\n",
      "step 968: loss=3.8432199954986572\n",
      "step 969: loss=3.7990047931671143\n",
      "step 970: loss=3.7246756553649902\n",
      "step 971: loss=3.711846113204956\n",
      "step 972: loss=3.7594316005706787\n",
      "step 973: loss=3.83084774017334\n",
      "step 974: loss=3.6742987632751465\n",
      "step 975: loss=3.684211015701294\n",
      "step 976: loss=3.766167163848877\n",
      "step 977: loss=3.725360155105591\n",
      "step 978: loss=3.788503408432007\n",
      "step 979: loss=3.7539544105529785\n",
      "step 980: loss=3.74045467376709\n",
      "step 981: loss=3.6661877632141113\n",
      "step 982: loss=3.8223159313201904\n",
      "step 983: loss=3.707447052001953\n",
      "step 984: loss=3.723768949508667\n",
      "step 985: loss=3.678398609161377\n",
      "step 986: loss=3.639932155609131\n",
      "step 987: loss=3.683429718017578\n",
      "step 988: loss=3.703873634338379\n",
      "step 989: loss=3.670771360397339\n",
      "step 990: loss=3.747714042663574\n",
      "step 991: loss=3.8158376216888428\n",
      "step 992: loss=3.765026569366455\n",
      "step 993: loss=3.719977617263794\n",
      "step 994: loss=3.709388017654419\n",
      "step 995: loss=3.685523271560669\n",
      "step 996: loss=3.697873115539551\n",
      "step 997: loss=3.727125883102417\n",
      "step 998: loss=3.804948091506958\n",
      "step 999: loss=3.704137086868286\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(1000):\n",
    "    \n",
    "    xb, yb = get_batch('train')\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    logits, loss = m(xb, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"step {steps}: loss={loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d90e706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wh;;Sq.f ustNzknc\n",
      "kwgOj$dhPWr,SV?hsusiKpgXXUh;Apmem d?hESXI.i;TrJgkiF-oKbXCAA -botrngFCHAUQkn$\n",
      "\n",
      "pn$w-gHoi?wtd!\n",
      "LLULIfSK'bAw :M.ZtOptXEQcL?hfaofqbPd?OnonQQJMap$aypupIBYGUsZaI'ottllo..k$W$Akp?yl?ajKlzY!lx&QQLW? t,bXFkyhl-dmVsHeckhRl,jSClgjuk:3Iv\n",
      "?OqlrV;!Plxfzgy;;\n",
      "'mRjuBQ&xk!$\n",
      "h\n",
      "SiruDJgKuDny,S$ERf.?GSV\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e2c0a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "724c07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8685973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "wei\n",
    "xbow2 = wei @ x # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c31625c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbdff502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28f821b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "=========\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "=========\n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a / torch.sum(a, dim=1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a@b\n",
    "print('=========')\n",
    "print(a)\n",
    "print('=========')\n",
    "print(b)\n",
    "print('=========')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db7eb657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "876ebc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "881e1828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "# out = wei @ x\n",
    "\n",
    "v= value(x)\n",
    "out = wei @ v # (B, T, T) @ (B, T, 16) -> (B, T, 16)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "102eea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb75b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5  # 这里乘以 head_size 的负 1/2 次方，是为了进行缩放（\"Scaled Dot-Product Attention\"），防止随着维度变大，点积值过大导致 softmax 梯度过小（变平），有助于保持数值稳定性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6de652db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.arange(0, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48aca28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.7943, 0.6310, 0.5012, 0.3981, 0.3162, 0.2512, 0.1995, 0.1585,\n",
      "        0.1259, 0.1000, 0.0794, 0.0631, 0.0501, 0.0398, 0.0316, 0.0251, 0.0200,\n",
      "        0.0158, 0.0126])\n"
     ]
    }
   ],
   "source": [
    "# 也就是数学公式：base^(-2i/d)\n",
    "inv_freq = 1.0 / (100 ** (torch.arange(0, 40, 2).float() / 40))\n",
    "print(inv_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33d7fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([1,2,3])\n",
    "inv_freq = torch.tensor([1,2,3])\n",
    "\n",
    "freqs = torch.einsum('i,j->ij', t, inv_freq)\n",
    "print(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f1e4778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4])\n",
    "print(x[..., :2])\n",
    "print(x[..., 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88eecc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "tril = torch.tril(torch.ones(4, 4))\n",
    "x = torch.zeros(4, 4)\n",
    "x.masked_fill_(tril == 0, float('-inf'))\n",
    "x = F.softmax(x, dim=-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15384e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "测试 1: 基础的 mask 索引\n",
      "==================================================\n",
      "初始 output (形状 torch.Size([4, 3])):\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "mask: tensor([ True, False,  True, False])\n",
      "mask.sum() = 2 (有几个 True)\n",
      "n = 2\n",
      "\n",
      "expert_output (形状 torch.Size([2, 3])):\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "expert_weights (形状 torch.Size([2, 1])):\n",
      "tensor([[0.8000],\n",
      "        [0.6000]])\n",
      "\n",
      "更新后的 output (形状 torch.Size([4, 3])):\n",
      "tensor([[0.8000, 1.6000, 2.4000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [2.4000, 3.0000, 3.6000],\n",
      "        [0.0000, 0.0000, 0.0000]])\n",
      "\n",
      "注意: 只有 token 0 和 token 2 被更新了！\n",
      "\n",
      "==================================================\n",
      "测试 2: 模拟多个专家累加\n",
      "==================================================\n",
      "专家 A 选中 token 0, 2，输出=10，权重=[0.5, 0.5]\n",
      "专家 B 选中 token 0, 3，输出=100，权重=[0.5, 0.8]\n",
      "\n",
      "专家 A 处理后:\n",
      "tensor([[5., 5., 5.],\n",
      "        [0., 0., 0.],\n",
      "        [5., 5., 5.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "专家 B 处理后 (累加):\n",
      "tensor([[55., 55., 55.],\n",
      "        [ 0.,  0.,  0.],\n",
      "        [ 5.,  5.,  5.],\n",
      "        [80., 80., 80.]])\n",
      "\n",
      "分析:\n",
      "- Token 0: 被 A 和 B 都选中 -> 0.5*10 + 0.5*100 = 55\n",
      "- Token 1: 没人选 -> 0\n",
      "- Token 2: 只被 A 选中 -> 0.5*10 = 5\n",
      "- Token 3: 只被 B 选中 -> 0.8*100 = 80\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "测试 PyTorch 中 mask 布尔索引的写法\n",
    "演示 output[mask] += ... 的行为\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"测试 1: 基础的 mask 索引\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 假设有 4 个 token (B*T = 4)，嵌入维度 C = 3\n",
    "B_T = 4\n",
    "C = 3\n",
    "\n",
    "# 初始化 output 为全 0\n",
    "output = torch.zeros(B_T, C)\n",
    "print(f\"初始 output (形状 {output.shape}):\")\n",
    "print(output)\n",
    "\n",
    "# mask: 标记哪些 token 选中了当前专家\n",
    "# 假设 token 0 和 token 2 选中了当前专家\n",
    "mask = torch.tensor([True, False, True, False])\n",
    "print(f\"\\nmask: {mask}\")\n",
    "print(f\"mask.sum() = {mask.sum()} (有几个 True)\")\n",
    "\n",
    "# n = 选中专家的 token 数量\n",
    "n = mask.sum().item()\n",
    "print(f\"n = {n}\")\n",
    "\n",
    "# 专家计算结果 (只有 n 个)\n",
    "expert_output = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],   # token 0 的专家输出\n",
    "    [4.0, 5.0, 6.0],   # token 2 的专家输出\n",
    "])\n",
    "print(f\"\\nexpert_output (形状 {expert_output.shape}):\")\n",
    "print(expert_output)\n",
    "\n",
    "# 权重 (只有 n 个)\n",
    "expert_weights = torch.tensor([[0.8], [0.6]])  # 形状 (n, 1)\n",
    "print(f\"\\nexpert_weights (形状 {expert_weights.shape}):\")\n",
    "print(expert_weights)\n",
    "\n",
    "# 关键操作：只更新 mask 为 True 的位置\n",
    "output[mask] += expert_weights * expert_output\n",
    "\n",
    "print(f\"\\n更新后的 output (形状 {output.shape}):\")\n",
    "print(output)\n",
    "print(\"\\n注意: 只有 token 0 和 token 2 被更新了！\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"测试 2: 模拟多个专家累加\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 重新初始化\n",
    "output = torch.zeros(B_T, C)\n",
    "\n",
    "# 专家 A: token 0, 2 选中\n",
    "mask_A = torch.tensor([True, False, True, False])\n",
    "expert_A_output = torch.ones(2, C) * 10  # 专家 A 输出全是 10\n",
    "weights_A = torch.tensor([[0.5], [0.5]])\n",
    "\n",
    "# 专家 B: token 0, 3 选中\n",
    "mask_B = torch.tensor([True, False, False, True])\n",
    "expert_B_output = torch.ones(2, C) * 100  # 专家 B 输出全是 100\n",
    "weights_B = torch.tensor([[0.5], [0.8]])\n",
    "\n",
    "print(\"专家 A 选中 token 0, 2，输出=10，权重=[0.5, 0.5]\")\n",
    "print(\"专家 B 选中 token 0, 3，输出=100，权重=[0.5, 0.8]\")\n",
    "\n",
    "# 模拟循环中的累加\n",
    "output[mask_A] += weights_A * expert_A_output\n",
    "print(f\"\\n专家 A 处理后:\")\n",
    "print(output)\n",
    "\n",
    "output[mask_B] += weights_B * expert_B_output\n",
    "print(f\"\\n专家 B 处理后 (累加):\")\n",
    "print(output)\n",
    "\n",
    "print(\"\\n分析:\")\n",
    "print(\"- Token 0: 被 A 和 B 都选中 -> 0.5*10 + 0.5*100 = 55\")\n",
    "print(\"- Token 1: 没人选 -> 0\")\n",
    "print(\"- Token 2: 只被 A 选中 -> 0.5*10 = 5\")\n",
    "print(\"- Token 3: 只被 B 选中 -> 0.8*100 = 80\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff75aa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_yarn_vs_rope():\n",
    "    # --- 1. 设置参数 ---\n",
    "    dim = 128          # 隐藏层维度 (为了看清楚，设小一点，实际是768或4096)\n",
    "    base = 10000       # RoPE的基数\n",
    "    scale = 4.0        # 我们要扩展4倍长度 (例如 512 -> 2048)\n",
    "    original_max = 512 # 原始模型训练长度\n",
    "    \n",
    "    # YaRN 的阈值参数\n",
    "    beta_fast = 32\n",
    "    beta_slow = 1\n",
    "\n",
    "    # --- 2. 计算原始 RoPE 频率 (Standard) ---\n",
    "    # 维度索引: 0, 2, 4, ... 126\n",
    "    indices = torch.arange(0, dim, 2).float()\n",
    "    # 原始频率公式: 1 / 10000^(i/d)\n",
    "    inv_freq_original = 1.0 / (base ** (indices / dim))\n",
    "\n",
    "    # --- 3. 计算 YaRN 频率 ---\n",
    "    # A. 插值频率 (全拉伸)\n",
    "    inv_freq_interpolated = 1.0 / (scale * base ** (indices / dim))\n",
    "\n",
    "    # B. 计算波长 (Wavelength) = 2pi / freq\n",
    "    wavelen = 2 * math.pi / inv_freq_original\n",
    "\n",
    "    # C. 计算 Ramp (混合比例)\n",
    "    # 这里的逻辑：波长越长(低频)，ramp越接近1，越需要插值\n",
    "    ramp = (wavelen / original_max - beta_slow) / (beta_fast - beta_slow)\n",
    "    ramp = torch.clamp(ramp, 0.0, 1.0)\n",
    "\n",
    "    # D. 混合 (Mix)\n",
    "    # ramp=0 (高频细节) -> 用原始\n",
    "    # ramp=1 (低频宏观) -> 用插值\n",
    "    inv_freq_yarn = (1 - ramp) * inv_freq_original + ramp * inv_freq_interpolated\n",
    "\n",
    "    # --- 4. 画图 ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # 画线\n",
    "    plt.plot(indices.numpy(), inv_freq_original.numpy(), label='Original RoPE (Standard)', color='red', linewidth=2)\n",
    "    plt.plot(indices.numpy(), inv_freq_yarn.numpy(), label='YaRN Scaled (4x)', color='blue', linestyle='--', linewidth=2.5)\n",
    "\n",
    "    # 标注区域\n",
    "    plt.axvline(x=0, color='gray', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # 装饰\n",
    "    plt.title(f'RoPE vs YaRN Frequency Curve (Dim={dim}, Scale={scale}x)', fontsize=14)\n",
    "    plt.xlabel('Dimension Index (Hidden Size)', fontsize=12)\n",
    "    plt.ylabel('Frequency (1/Wavelength)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 重点：为了看清\"快速下降\"和\"尾部差异\"，通常看对数坐标更清晰\n",
    "    # 如果你想看直观的\"滑梯\"，可以注释掉下面这行\n",
    "    plt.yscale('log') \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 运行\n",
    "plot_yarn_vs_rope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc6702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
